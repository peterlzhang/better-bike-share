{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## output bikeshare density for what area could support\n",
    "## output bikeability based on strava data to decide if area is a good idea\n",
    "## Assumes that bike shares are optimally placed and near optimal capacity\n",
    "## use regularization in the training of the ML model\n",
    "\n",
    "import pandas as pd\n",
    "import pandas_profiling\n",
    "import geopandas as gpd\n",
    "import osmnx as ox\n",
    "import folium\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from shapely.geometry import Point, Polygon, MultiPolygon\n",
    "from shapely.ops import nearest_points\n",
    "import branca.colormap as cm\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workaround to fix chrome issue where folium won't plot maps with a large number of layers\n",
    "# See comment by dstein64 at: https://github.com/python-visualization/folium/issues/812\n",
    "\n",
    "import base64\n",
    "def _repr_html_(self, **kwargs):\n",
    "    html = base64.b64encode(self.render(**kwargs).encode('utf8')).decode('utf8')\n",
    "    onload = (\n",
    "        'this.contentDocument.open();'\n",
    "        'this.contentDocument.write(atob(this.getAttribute(\\'data-html\\')));'\n",
    "        'this.contentDocument.close();'\n",
    "    )\n",
    "    if self.height is None:\n",
    "        iframe = (\n",
    "            '<div style=\"width:{width};\">'\n",
    "            '<div style=\"position:relative;width:100%;height:0;padding-bottom:{ratio};\">'\n",
    "            '<iframe src=\"about:blank\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;'\n",
    "            'border:none !important;\" '\n",
    "            'data-html={html} onload=\"{onload}\" '\n",
    "            'allowfullscreen webkitallowfullscreen mozallowfullscreen>'\n",
    "            '</iframe>'\n",
    "            '</div></div>').format\n",
    "        iframe = iframe(html=html, onload=onload, width=self.width, ratio=self.ratio)\n",
    "    else:\n",
    "        iframe = ('<iframe src=\"about:blank\" width=\"{width}\" height=\"{height}\"'\n",
    "                  'style=\"border:none !important;\" '\n",
    "                  'data-html={html} onload=\"{onload}\" '\n",
    "                  '\"allowfullscreen\" \"webkitallowfullscreen\" \"mozallowfullscreen\">'\n",
    "                  '</iframe>').format\n",
    "        iframe = iframe(html=html, onload=onload, width=self.width, height=self.height)\n",
    "    return iframe\n",
    "\n",
    "folium.branca.element.Figure._repr_html_ = _repr_html_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridify_polygon(poly,grid_spacing):\n",
    "    # creates a cartesian grid inside polygon with the input grid_spacing\n",
    "    # poly: polygon which we want a grid inside\n",
    "    # grid_spacing: spaceing in lattitude/longitude degrees\n",
    "    poly_xmin,poly_ymin,poly_xmax,poly_ymax = poly.geometry.total_bounds\n",
    "\n",
    "    cols = list(np.arange(poly_xmin,poly_xmax+grid_spacing,grid_spacing))\n",
    "    rows = list(np.arange(poly_ymin,poly_ymax+grid_spacing,grid_spacing))\n",
    "    rows.reverse()\n",
    "\n",
    "    polygons = []\n",
    "    for x in cols:\n",
    "        for y in rows:\n",
    "            polygons.append( Polygon([(x,y), (x+grid_spacing, y), (x+grid_spacing, y-grid_spacing), (x, y-grid_spacing)]) )\n",
    "\n",
    "    grid = gpd.GeoDataFrame({'geometry':polygons})\n",
    "\n",
    "    grid['isin_poly'] = grid.apply(lambda row: row['geometry'].centroid.within(poly.geometry[0]), axis=1)\n",
    "    poly_grid = grid[grid.isin_poly == True]\n",
    "    poly_grid.crs = {'init': 'epsg:4326', 'no_defs': True}\n",
    "    poly_grid = poly_grid.drop(['isin_poly'], axis = 1)\n",
    "    \n",
    "    # Calculate the polygon areas in km\n",
    "    poly_grid_cart = poly_grid.copy()\n",
    "    poly_grid_cart = poly_grid_cart.to_crs({'init': 'epsg:3857'})\n",
    "    poly_grid_cart['poly_area_km'] = poly_grid_cart['geometry'].area/ 10**6\n",
    "    # Store polygon area\n",
    "    poly_grid['poly_area_km'] = poly_grid_cart['poly_area_km']\n",
    "    \n",
    "    # \n",
    "    poly_grid = poly_grid.reset_index()\n",
    "    return poly_grid\n",
    "\n",
    "def amenity_in_polygon(amenity_points,poly):\n",
    "    # returns the amenities that are inside the given polygon\n",
    "    # When there are zero amenities within the interrogation region, the function returns an empty dataframe as\n",
    "    # as expected, but also prints out a lot of errors. not a huge issue but annoying.\n",
    "    # Maybe implement a test for if empty, return 0\n",
    "    # Example use:\n",
    "    #         amenity_in_polygon(food_amenities,city_grid.geometry.iloc[38])\n",
    "    \n",
    "    # Generate boolean list of whether amenity is in polygon\n",
    "    indices = amenity_points.apply(lambda row: row['geometry'].within(poly), axis=1)\n",
    "    if not any(indices): # If all indices are false\n",
    "        return pd.DataFrame(columns=['A']) # return empty dataframe (not sure what is best to output here )\n",
    "    else:\n",
    "        return amenity_points[amenity_points.apply(lambda row: row['geometry'].within(poly), axis=1)]\n",
    "\n",
    "def avg_dist_to_amenities(interrogation_point,amenity_df,n):\n",
    "    # calculates the mean distance of the n nearest amenities to the interrogation point\n",
    "    # If there are less than n amenities in the search it'll just return the average of the known amenities.\n",
    "    # Example: avg_dist_to_amenities(city_grid.geometry.iloc[39],food_amenities,5)\n",
    "    dist_to_amenity = amenity_df['geometry'].apply(lambda x: x.distance(interrogation_point))\n",
    "    dist_to_amenity.sort_values(inplace=True)\n",
    "    dist_to_amenity[:5]\n",
    "    if len(dist_to_amenity) >= n:\n",
    "        return dist_to_amenity[:n].mean()\n",
    "    elif len(dist_to_amenity) == 0:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return dist_to_amenity.mean()\n",
    "    \n",
    "    \n",
    "# Generate features dataframe by finding the count of each unique amenity in each region\n",
    "def features_density(interrogation_grid,osm_features,targets):\n",
    "    # Calculate feature and target density inside a series of polygons\n",
    "    # INPUTS\n",
    "    # ------\n",
    "    # Interrogation grid: list of polygons in which to calculate density of features and targets\n",
    "    # osm_features: gdf of amenities in area retrieved from OSM\n",
    "    # targest: gdf of target locations\n",
    "    # OUTPUTS\n",
    "    # -------\n",
    "    # cleaned_df: contains the density of features and targets in the interrogation grid\n",
    "    # create new cleaned df that will store features and target data\n",
    "    cleaned_df = interrogation_grid.copy()\n",
    "    cleaned_df = cleaned_df.reset_index()\n",
    "    cleaned_df['bike_rental_density'] = 0\n",
    "    cleaned_df = cleaned_df.reindex(cleaned_df.columns.tolist() + amenity_names, axis=1) \n",
    "\n",
    "\n",
    "    # loop through grid points and populate features.\n",
    "    for index, row in cleaned_df.iterrows():\n",
    "        grid_pt = cleaned_df.geometry.iloc[index]\n",
    "        amenities_in_grid = amenity_in_polygon(osm_features,grid_pt)\n",
    "\n",
    "        # fill amenity rows with counts inside each polygon\n",
    "        if len(amenities_in_grid) > 0:\n",
    "            amenity_counts = amenities_in_grid['amenity'].value_counts()\n",
    "            for val, cnt in amenity_counts.iteritems():\n",
    "                # test if value is in list of features that are selected for ML model\n",
    "                if val in amenity_names:\n",
    "                    cleaned_df[val].iloc[index] = cnt / cleaned_df.poly_area_km.iloc[index]\n",
    "\n",
    "        # add target column for bike rentals\n",
    "        bike_rentals_in_grid = amenity_in_polygon(targets,grid_pt)\n",
    "        if len(bike_rentals_in_grid) > 0:\n",
    "            cleaned_df['bike_rental_density'].iloc[index] = len(bike_rentals_in_grid) / cleaned_df.poly_area_km.iloc[index]\n",
    "        else:\n",
    "            cleaned_df['bike_rental_density'].iloc[index] = 0\n",
    "\n",
    "    # remove nan values\n",
    "    cleaned_df[amenity_names] = cleaned_df[amenity_names].fillna(0)\n",
    "    # remove unecessary columns\n",
    "    cleaned_df = cleaned_df.drop(columns = ['level_0','index'])\n",
    "    # relable as density \n",
    "    new_names = [name + '_density' for name in amenity_names]\n",
    "    cleaned_df.rename(columns = dict(zip(amenity_names, new_names)), inplace=True)\n",
    "    \n",
    "    return cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = 'OSM_geo_data/'\n",
    "city_names = ['austin','berkeley','boston','chicago','denver','glasgow','los_angeles',\n",
    "              'minneapolis','montreal','new_york','san_francisco','salt_lake_city','phoenix',\n",
    "             'columbus']\n",
    "\n",
    "\n",
    "\n",
    "# filename_grid = folder_name + city_name + '_grid.geojson'\n",
    "# filename_amenities = folder_name + city_name + '_amenities.geojson'\n",
    "# filename_bike_rentals = folder_name + city_name + '_bike_rentals.geojson'\n",
    "\n",
    "# Initialize dataframe\n",
    "df = pd.DataFrame()\n",
    "city_grid = pd.DataFrame()\n",
    "\n",
    "for name in city_names:\n",
    "    filename_cleaned_df = folder_name + name + '_feature_target_table.geojson'\n",
    "    filename_grid = folder_name + name + '_grid.geojson'\n",
    "    if df.empty:\n",
    "        df = gpd.read_file(filename_cleaned_df)\n",
    "        city_grid = gpd.read_file(filename_grid)\n",
    "    else:\n",
    "        df = df.append(gpd.read_file(filename_cleaned_df), ignore_index=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature and target labels\n",
    "features = ['pharmacy_density', 'recycling_density', 'place_of_worship_density', 'post_box_density',\n",
    "            'library_density', 'post_office_density', 'parking_density', 'fuel_density', 'bank_density',\n",
    "            'pub_density', 'telephone_density', 'toilets_density', 'taxi_density', 'bicycle_parking_density',\n",
    "            'motorcycle_parking_density', 'fast_food_density', 'bar_density', 'life_boats_density',\n",
    "            'restaurant_density', 'arts_centre_density', 'music_venue_density', 'nightclub_density',\n",
    "            'cafe_density', 'atm_density', 'community_centre_density', 'jobcentre_density', 'doctors_density',\n",
    "            'cinema_density', 'grave_yard_density', 'police_density', 'bus_station_density', 'theatre_density',\n",
    "            'bureau_de_change_density', 'hospital_density', 'bench_density', 'school_density', 'courthouse_density',\n",
    "            'ice_cream_density', 'fountain_density', 'left_luggage_density', 'drinking_water_density',\n",
    "            'casino_density', 'car_rental_density', 'car_wash_density', 'ferry_terminal_density', 'dentist_density',\n",
    "            'townhall_density', 'shelter_density', 'parking_entrance_density', 'conference_centre_density',\n",
    "            'marketplace_density', 'vending_machine_density', 'waste_basket_density', 'clock_density',\n",
    "            'studio_density', 'veterinary_density', 'gallery_density', 'gambling_density', 'kindergarten_density',\n",
    "            'social_facility_density', 'charging_station_density', 'car_sharing_density', 'clinic_density',\n",
    "            'water_density', 'compressed_air_density', 'public_building_density', 'social_centre_density',\n",
    "            'childcare_density', 'grit_bin_density', 'bicycle_repair_station_density', 'events_venue_density',\n",
    "            'embassy_density', 'college_density', 'circus_school_density', 'parcel_lockers_density',\n",
    "            'money_transfer_density', 'photo_booth_density', 'luggage_locker_density', 'university_density',\n",
    "            'venue_density', 'swimming_pool_density', 'fire_station_density', 'post_depot_density',\n",
    "            'crematorium_density', 'sport_density', 'nursing_home_density', 'biergarten_density', 'garden_density',\n",
    "            'prison_density', 'club_density', 'parking_space_density', 'trailer_park_density', 'archive_density',\n",
    "            'monastery_density']\n",
    "target = ['bike_rental_density']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d72cba6d36d941ad84c65160d5a4a926",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(HTML(value='<div id=\"overview-content\" class=\"row variable spacing\">\\n    <div class=\"row\">\\n   â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Report generated with <a href=\"https://github.com/pandas-profiling/pandas-profiling\">pandas-profiling</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Profile features collected from OSM and check for correlation\n",
    "pandas_profiling.ProfileReport(df[features])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.02, random_state=1)\n",
    "\n",
    "pos_target = len(y[y.bike_rental_density != 0])\n",
    "neg_target = len(y[y.bike_rental_density == 0])\n",
    "print(pos_target,neg_target,pos_target/neg_target)\n",
    "\n",
    "sns.distplot(y.bike_rental_density);\n",
    "print('Linear regression is not the best option given that the target is highly skewed towards 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Linear model\n",
    "LM_model = LinearRegression()\n",
    "LM_model.fit(X_train,y_train)\n",
    "LM_y_pred = LM_model.predict(X_test)\n",
    "\n",
    "## Lasso\n",
    "lasso_rmse = []\n",
    "ridge_rmse = []\n",
    "EN_rmse = []\n",
    "alpha_ref = np.linspace(0.001,1,101)\n",
    "\n",
    "for ind, alpha in enumerate(alpha_ref):\n",
    "    \n",
    "    lasso_model = Lasso(alpha=alpha)\n",
    "    lasso_model.fit(X_train,y_train)\n",
    "    lasso_y_pred = lasso_model.predict(X_test)\n",
    "    lasso_rmse.append(metrics.mean_absolute_error(y_test,lasso_y_pred))\n",
    "    \n",
    "    \n",
    "    ridge_model = Ridge(alpha = alpha)\n",
    "    ridge_model.fit(X_train,y_train)\n",
    "    ridge_y_pred = ridge_model.predict(X_test)\n",
    "    ridge_rmse.append(metrics.mean_absolute_error(y_test,lasso_y_pred))\n",
    "    \n",
    "    EN_model = ElasticNet(alpha = alpha)\n",
    "    EN_model.fit(X_train,y_train)\n",
    "    EN_y_pred = EN_model.predict(X_test)\n",
    "    EN_rmse.append(metrics.mean_absolute_error(y_test,lasso_y_pred))\n",
    "\n",
    "\n",
    "## Random Forest\n",
    "# RF_model = RandomForestRegressor(random_state = 2,max_depth = 9,max_leaf_nodes = 67)\n",
    "RF_model = RandomForestRegressor()\n",
    "RF_model.fit(X_train,y_train)\n",
    "RF_y_pred = RF_model.predict(X_test)\n",
    "\n",
    "# remove negative predictions\n",
    "# y_pred[y_pred <0] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Linear regression isn't the best option given that the target is highly skewed towards 0\n",
    "\n",
    "print('Multivariate linear regression mean absolute error (MAE): %4.3f' % metrics.mean_absolute_error(y_test,LM_y_pred))\n",
    "print('Lasso mean absolute error (MAE): %4.3f and alpha = %4.3f' % (min(lasso_rmse),alpha_ref[np.argmin(lasso_rmse)]))\n",
    "print('Ridge mean absolute error (MAE): %4.3f and alpha = %4.3f' % (min(ridge_rmse),alpha_ref[np.argmin(ridge_rmse)]))\n",
    "print('Elastic Net mean absolute error (MAE): %4.3f and alpha = %4.3f' % (min(EN_rmse),alpha_ref[np.argmin(EN_rmse)]))\n",
    "\n",
    "print('Random forest mean absolute error (MAE): %4.3f' % metrics.mean_absolute_error(y_test,RF_y_pred))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = y_test.copy()\n",
    "comparison['LM_y_pred'] = LM_y_pred\n",
    "comparison['RF_y_pred'] = RF_y_pred\n",
    "comparison['Lasso_y_pred'] = lasso_y_pred\n",
    "comparison.head()\n",
    "\n",
    "# diff = comparison.y_pred - comparison.bike_rental_density\n",
    "# comparison['difference'] = diff\n",
    "# comparison['bike_share_score'] =  y_pred / max(y_pred)\n",
    "# # y_pred\n",
    "# comparison\n",
    "\n",
    "# # get grid index of positive bike share locations\n",
    "# bike_share_pos_ind = list(comparison.index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Start validation on unseen city, \n",
    "place = 'Portland, Oregon, USA'\n",
    "\n",
    "# city_grid = gpd.read_file(filename_grid)\n",
    "# all_amenities = gpd.read_file(filename_amenities)\n",
    "# bike_rentals = gpd.read_file(filename_bike_rentals)\n",
    "\n",
    "# Generate city grid for interrogation\n",
    "city = ox.gdf_from_place(place)\n",
    "portland_grid = gpd.read_file(folder_name + 'portland_grid.geojson')\n",
    "portland_ft = gpd.read_file(folder_name + 'portland_feature_target_table.geojson')\n",
    "portland_bike_rentals = gpd.read_file(folder_name + 'portland_bike_rentals.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portland_ft.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portland_predict = RF_model.predict(portland_ft[features])\n",
    "portland_comparison = portland_grid.copy()\n",
    "portland_comparison['bike_rental_density'] = portland_ft['bike_rental_density'] \n",
    "portland_comparison['RF_prediction'] = portland_predict\n",
    "\n",
    "scale_factor = max(max(portland_predict),max(portland_comparison.bike_rental_density))\n",
    "\n",
    "portland_comparison['scaled_actual_density'] = portland_ft['bike_rental_density'] / scale_factor\n",
    "portland_comparison['scaled_pred_density'] = portland_comparison['RF_prediction'] / scale_factor\n",
    "\n",
    "print('Random forest mean absolute error (MAE): %4.3f' % metrics.mean_absolute_error(portland_comparison.bike_rental_density,portland_comparison.RF_prediction))\n",
    "# RMSE is low because most of the grid cells are empty and random forest captures that well. Does this misrepresent the accuracty?\n",
    "# Results could be improved with bike friendliness score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(portland_comparison.bike_rental_density - portland_comparison.RF_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dictionaries for opacity and colormaps\n",
    "pred_dict = portland_comparison['scaled_pred_density']\n",
    "actual_dict = portland_comparison['scaled_actual_density']\n",
    "diff_dict = (portland_comparison['bike_rental_density'] - portland_comparison['RF_prediction'])\n",
    "\n",
    "pred_opacity = {str(key): pred_dict[key] for key in pred_dict.keys()}\n",
    "actual_opacity = {str(key): actual_dict[key] for key in actual_dict.keys()}\n",
    "diff_opacity = {str(key): abs(diff_dict[key]) for key in diff_dict.keys()}\n",
    "\n",
    "colormap = cm.linear.RdBu_11.scale(-scale_factor,scale_factor)\n",
    "# colormap = cm.LinearColormap(colors=['yellow','white','green'],vmin=0,vmax=scale_factor)\n",
    "\n",
    "diff_color = {str(key): colormap(diff_dict[key]) for key in diff_dict.keys()}\n",
    "colormap\n",
    "\n",
    "# color_dict = {key: colormap(unemployment_dict[key]) for key in unemployment_dict.keys()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "m = folium.Map([city.geometry.centroid.y, city.geometry.centroid.x],\n",
    "               zoom_start=11,\n",
    "               tiles=\"CartoDb positron\")\n",
    "\n",
    "style_city = {'color':'#ebc923 ', 'fillColor': '#ebc923 ', 'weight':'1', 'fillOpacity' : 0.1}\n",
    "folium.GeoJson(city,\n",
    "               style_function=lambda x: style_city,\n",
    "               name='City Limit').add_to(m)\n",
    "\n",
    "# Plot actual bike share density\n",
    "folium.GeoJson(\n",
    "    portland_comparison['geometry'],\n",
    "    name='Actual bike share density',\n",
    "    style_function=lambda feature: {\n",
    "        'fillColor': '#1FFD09',\n",
    "        'color': 'black',\n",
    "        'weight': 0,\n",
    "        'fillOpacity': actual_opacity[feature['id']],\n",
    "    }\n",
    ").add_to(m)\n",
    "\n",
    "# plot predictions of bike share density\n",
    "folium.GeoJson(\n",
    "    portland_comparison['geometry'],\n",
    "    name='Prediction: bike share density',\n",
    "    style_function=lambda feature: {\n",
    "        'fillColor': '#1FFD09',\n",
    "        'color': 'black',\n",
    "        'weight': 0,\n",
    "        'fillOpacity': pred_opacity[feature['id']],\n",
    "    }\n",
    ").add_to(m)\n",
    "\n",
    "# plot difference between predicted and actual\n",
    "# folium.GeoJson(\n",
    "#     portland_comparison['geometry'],\n",
    "#     name='Difference: bike share density',\n",
    "#     style_function=lambda feature: {\n",
    "#         'fillColor': '#1FFD09',\n",
    "#         'color': 'black',\n",
    "#         'weight': 0,\n",
    "#         'fillOpacity': diff_opacity[feature['id']],\n",
    "#     }\n",
    "# ).add_to(m)\n",
    "\n",
    "folium.GeoJson(\n",
    "    portland_comparison['geometry'],\n",
    "    name='Difference: bike share density',\n",
    "    style_function=lambda feature: {\n",
    "        'fillColor': diff_color[feature['id']],\n",
    "        'color': 'black',\n",
    "        'weight': 0,\n",
    "#         'fillOpacity': 0.5,\n",
    "        'fillOpacity': diff_opacity[feature['id']],\n",
    "    }\n",
    ").add_to(m)\n",
    "\n",
    "colormap.caption = 'Difference in bike density prediction'\n",
    "colormap.add_to(m)\n",
    "\n",
    "\n",
    "# for index, row in portland_comparison.iterrows():\n",
    "#     folium.Choropleth(portland_grid.geometry[portland_grid.index == index], fill_color = '#1FFD09',\n",
    "#                       fill_opacity = portland_comparison.scaled_pred_density.loc[index]).add_to(m)\n",
    "\n",
    "# folium.Choropleth(portland_grid.geometry.iloc[40],color = 'green')\n",
    "\n",
    "# plot bikable streets\n",
    "# m = folium.Map(latlon,\n",
    "#                zoom_start=15,\n",
    "#                tiles=\"CartoDb dark_matter\")\n",
    "# folium.GeoJson(streets, style_function=lambda x: style).add_to(m)\n",
    "\n",
    "# add cafes\n",
    "# locs = zip(all_amenities.geometry.y, all_amenities.geometry.x)\n",
    "# for location in locs:\n",
    "#     folium.CircleMarker(location=location, \n",
    "#         color = \"red\",   radius=1).add_to(m)\n",
    "\n",
    "# add bike rentals\n",
    "# locs = zip(portland_bike_rentals.geometry.centroid.y, portland_bike_rentals.geometry.centroid.x)\n",
    "# for location in locs:\n",
    "#     folium.CircleMarker(location=location, \n",
    "#         color = \"yellow\",   radius=2, fill=True).add_to(m)\n",
    "\n",
    "folium.LayerControl().add_to(m)\n",
    "\n",
    "# m.save(\"portland_validation.html\")\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
