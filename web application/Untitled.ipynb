{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import html2text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "HtmlFile = open('portland_validation.html', 'r', encoding='utf-8')\n",
    "html_code = HtmlFile.read() \n",
    "\n",
    "html_text = html2text.HTML2Text(html_code)\n",
    "print(html_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package html2text:\n",
      "\n",
      "NAME\n",
      "    html2text - html2text: Turn HTML into equivalent Markdown-structured text.\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    __main__\n",
      "    cli\n",
      "    config\n",
      "    elements\n",
      "    typing\n",
      "    utils\n",
      "\n",
      "CLASSES\n",
      "    html.parser.HTMLParser(_markupbase.ParserBase)\n",
      "        HTML2Text\n",
      "    \n",
      "    class HTML2Text(html.parser.HTMLParser)\n",
      "     |  HTML2Text(out: Union[html2text.OutCallback, NoneType] = None, baseurl: str = '', bodywidth: int = 78) -> None\n",
      "     |  \n",
      "     |  Find tags and other markup and call handler functions.\n",
      "     |  \n",
      "     |  Usage:\n",
      "     |      p = HTMLParser()\n",
      "     |      p.feed(data)\n",
      "     |      ...\n",
      "     |      p.close()\n",
      "     |  \n",
      "     |  Start tags are handled by calling self.handle_starttag() or\n",
      "     |  self.handle_startendtag(); end tags by self.handle_endtag().  The\n",
      "     |  data between tags is passed from the parser to the derived class\n",
      "     |  by calling self.handle_data() with the data as argument (the data\n",
      "     |  may be split up in arbitrary chunks).  If convert_charrefs is\n",
      "     |  True the character references are converted automatically to the\n",
      "     |  corresponding Unicode character (and self.handle_data() is no\n",
      "     |  longer split in chunks), otherwise they are passed by calling\n",
      "     |  self.handle_entityref() or self.handle_charref() with the string\n",
      "     |  containing respectively the named or numeric reference as the\n",
      "     |  argument.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      HTML2Text\n",
      "     |      html.parser.HTMLParser\n",
      "     |      _markupbase.ParserBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, out: Union[html2text.OutCallback, NoneType] = None, baseurl: str = '', bodywidth: int = 78) -> None\n",
      "     |      Input parameters:\n",
      "     |          out: possible custom replacement for self.outtextf (which\n",
      "     |               appends lines of text).\n",
      "     |          baseurl: base URL of the document we process\n",
      "     |  \n",
      "     |  charref(self, name: str) -> str\n",
      "     |  \n",
      "     |  entityref(self, c: str) -> str\n",
      "     |  \n",
      "     |  feed(self, data: str) -> None\n",
      "     |      Feed data to the parser.\n",
      "     |      \n",
      "     |      Call this as often as you want, with as little or as much text\n",
      "     |      as you want (may include '\\n').\n",
      "     |  \n",
      "     |  finish(self) -> str\n",
      "     |  \n",
      "     |  google_nest_count(self, style: Dict[str, str]) -> int\n",
      "     |      Calculate the nesting count of google doc lists\n",
      "     |      \n",
      "     |      :type style: dict\n",
      "     |      \n",
      "     |      :rtype: int\n",
      "     |  \n",
      "     |  handle(self, data: str) -> str\n",
      "     |  \n",
      "     |  handle_charref(self, c: str) -> None\n",
      "     |  \n",
      "     |  handle_data(self, data: str, entity_char: bool = False) -> None\n",
      "     |  \n",
      "     |  handle_emphasis(self, start: bool, tag_style: Dict[str, str], parent_style: Dict[str, str]) -> None\n",
      "     |      Handles various text emphases\n",
      "     |  \n",
      "     |  handle_endtag(self, tag: str) -> None\n",
      "     |  \n",
      "     |  handle_entityref(self, c: str) -> None\n",
      "     |  \n",
      "     |  handle_starttag(self, tag: str, attrs: List[Tuple[str, Union[str, NoneType]]]) -> None\n",
      "     |  \n",
      "     |  handle_tag(self, tag: str, attrs: Dict[str, Union[str, NoneType]], start: bool) -> None\n",
      "     |  \n",
      "     |  o(self, data: str, puredata: bool = False, force: Union[bool, str] = False) -> None\n",
      "     |      Deal with indentation and whitespace\n",
      "     |  \n",
      "     |  optwrap(self, text: str) -> str\n",
      "     |      Wrap all paragraphs in the provided text.\n",
      "     |      \n",
      "     |      :type text: str\n",
      "     |      \n",
      "     |      :rtype: str\n",
      "     |  \n",
      "     |  outtextf(self, s: str) -> None\n",
      "     |  \n",
      "     |  p(self) -> None\n",
      "     |      Set pretty print to 1 or 2 lines\n",
      "     |  \n",
      "     |  pbr(self) -> None\n",
      "     |      Pretty print has a line break\n",
      "     |  \n",
      "     |  previousIndex(self, attrs: Dict[str, Union[str, NoneType]]) -> Union[int, NoneType]\n",
      "     |      :type attrs: dict\n",
      "     |      \n",
      "     |      :returns: The index of certain set of attributes (of a link) in the\n",
      "     |      self.a list. If the set of attributes is not found, returns None\n",
      "     |      :rtype: int\n",
      "     |  \n",
      "     |  soft_br(self) -> None\n",
      "     |      Soft breaks\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from html.parser.HTMLParser:\n",
      "     |  \n",
      "     |  check_for_whole_start_tag(self, i)\n",
      "     |      # Internal -- check to see if we have a complete starttag; return end\n",
      "     |      # or -1 if incomplete.\n",
      "     |  \n",
      "     |  clear_cdata_mode(self)\n",
      "     |  \n",
      "     |  close(self)\n",
      "     |      Handle any buffered data.\n",
      "     |  \n",
      "     |  get_starttag_text(self)\n",
      "     |      Return full source of start tag: '<...>'.\n",
      "     |  \n",
      "     |  goahead(self, end)\n",
      "     |      # Internal -- handle data as far as reasonable.  May leave state\n",
      "     |      # and data to be processed by a subsequent call.  If 'end' is\n",
      "     |      # true, force handling all data as if followed by EOF marker.\n",
      "     |  \n",
      "     |  handle_comment(self, data)\n",
      "     |      # Overridable -- handle comment\n",
      "     |  \n",
      "     |  handle_decl(self, decl)\n",
      "     |      # Overridable -- handle declaration\n",
      "     |  \n",
      "     |  handle_pi(self, data)\n",
      "     |      # Overridable -- handle processing instruction\n",
      "     |  \n",
      "     |  handle_startendtag(self, tag, attrs)\n",
      "     |      # Overridable -- finish processing of start+end tag: <tag.../>\n",
      "     |  \n",
      "     |  parse_bogus_comment(self, i, report=1)\n",
      "     |      # Internal -- parse bogus comment, return length or -1 if not terminated\n",
      "     |      # see http://www.w3.org/TR/html5/tokenization.html#bogus-comment-state\n",
      "     |  \n",
      "     |  parse_endtag(self, i)\n",
      "     |      # Internal -- parse endtag, return end or -1 if incomplete\n",
      "     |  \n",
      "     |  parse_html_declaration(self, i)\n",
      "     |      # Internal -- parse html declarations, return length or -1 if not terminated\n",
      "     |      # See w3.org/TR/html5/tokenization.html#markup-declaration-open-state\n",
      "     |      # See also parse_declaration in _markupbase\n",
      "     |  \n",
      "     |  parse_pi(self, i)\n",
      "     |      # Internal -- parse processing instr, return end or -1 if not terminated\n",
      "     |  \n",
      "     |  parse_starttag(self, i)\n",
      "     |      # Internal -- handle starttag, return end or -1 if not terminated\n",
      "     |  \n",
      "     |  reset(self)\n",
      "     |      Reset this instance.  Loses all unprocessed data.\n",
      "     |  \n",
      "     |  set_cdata_mode(self, elem)\n",
      "     |  \n",
      "     |  unescape(self, s)\n",
      "     |      # Internal -- helper to remove special character quoting\n",
      "     |  \n",
      "     |  unknown_decl(self, data)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from html.parser.HTMLParser:\n",
      "     |  \n",
      "     |  CDATA_CONTENT_ELEMENTS = ('script', 'style')\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from _markupbase.ParserBase:\n",
      "     |  \n",
      "     |  error(self, message)\n",
      "     |  \n",
      "     |  getpos(self)\n",
      "     |      Return current line number and offset.\n",
      "     |  \n",
      "     |  parse_comment(self, i, report=1)\n",
      "     |      # Internal -- parse comment, return length or -1 if not terminated\n",
      "     |  \n",
      "     |  parse_declaration(self, i)\n",
      "     |      # Internal -- parse declaration (for use by subclasses).\n",
      "     |  \n",
      "     |  parse_marked_section(self, i, report=1)\n",
      "     |      # Internal -- parse a marked section\n",
      "     |      # Override this to handle MS-word extension syntax <![if word]>content<![endif]>\n",
      "     |  \n",
      "     |  updatepos(self, i, j)\n",
      "     |      # Internal -- update line number and offset.  This should be\n",
      "     |      # called for each piece of data exactly once, in order -- in other\n",
      "     |      # words the concatenation of all the input strings to this\n",
      "     |      # function should be exactly the entire input.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from _markupbase.ParserBase:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "\n",
      "FUNCTIONS\n",
      "    html2text(html: str, baseurl: str = '', bodywidth: Union[int, NoneType] = None) -> str\n",
      "\n",
      "DATA\n",
      "    Dict = typing.Dict\n",
      "    List = typing.List\n",
      "    Optional = typing.Optional\n",
      "    Tuple = typing.Tuple\n",
      "    Union = typing.Union\n",
      "    unifiable_n = {169: '(C)', 183: '*', 224: 'a', 225: 'a', 226: 'a', 227...\n",
      "\n",
      "VERSION\n",
      "    (2020, 1, 16)\n",
      "\n",
      "FILE\n",
      "    /Users/peter/opt/anaconda3/lib/python3.7/site-packages/html2text/__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
